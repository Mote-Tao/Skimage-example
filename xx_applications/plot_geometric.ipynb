{
  "metadata": {
    "language_info": {
      "name": "python",
      "nbconvert_exporter": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "version": "3.4.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "nbformat_minor": 0,
  "cells": [
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "execution_count": null,
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "\n# Using geometric transformations\n\n\nIn this example, we will see how to use geometric transformations in the context\nof image processing.\n\n"
      ]
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "execution_count": null,
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom skimage import data\nfrom skimage import transform as tf"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Basics\n======\n\nSeveral different geometric transformation types are supported: similarity,\naffine, projective and polynomial.\n\nGeometric transformations can either be created using the explicit\nparameters (e.g. scale, shear, rotation and translation) or the\ntransformation matrix:\n\nFirst we create a transformation using explicit parameters:\n\n"
      ]
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "execution_count": null,
      "cell_type": "code",
      "source": [
        "tform = tf.SimilarityTransform(scale=1, rotation=math.pi/2,\n                               translation=(0, 1))\nprint(tform.params)"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Alternatively you can define a transformation by the transformation matrix\nitself:\n\n"
      ]
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "execution_count": null,
      "cell_type": "code",
      "source": [
        "matrix = tform.params.copy()\nmatrix[1, 2] = 2\ntform2 = tf.SimilarityTransform(matrix)"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "These transformation objects can then be used to apply forward and inverse\ncoordinate transformations between the source and destination coordinate\nsystems:\n\n"
      ]
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "execution_count": null,
      "cell_type": "code",
      "source": [
        "coord = [1, 0]\nprint(tform2(coord))\nprint(tform2.inverse(tform(coord)))"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Image warping\n=============\n\nGeometric transformations can also be used to warp images:\n\n"
      ]
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "execution_count": null,
      "cell_type": "code",
      "source": [
        "text = data.text()\n\ntform = tf.SimilarityTransform(scale=1, rotation=math.pi/4,\n                               translation=(text.shape[0]/2, -100))\n\nrotated = tf.warp(text, tform)\nback_rotated = tf.warp(rotated, tform.inverse)\n\nfig, ax = plt.subplots(nrows=3)\n\nax[0].imshow(text, cmap=plt.cm.gray)\nax[1].imshow(rotated, cmap=plt.cm.gray)\nax[2].imshow(back_rotated, cmap=plt.cm.gray)\n\nfor a in ax:\n    a.axis('off')\n\nplt.tight_layout()"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Parameter estimation\n====================\n\nIn addition to the basic functionality mentioned above you can also\nestimate the parameters of a geometric transformation using the least-\nsquares method.\n\nThis can amongst other things be used for image registration or\nrectification, where you have a set of control points or\nhomologous/corresponding points in two images.\n\nLet's assume we want to recognize letters on a photograph which was not\ntaken from the front but at a certain angle. In the simplest case of a\nplane paper surface the letters are projectively distorted. Simple matching\nalgorithms would not be able to match such symbols. One solution to this\nproblem would be to warp the image so that the distortion is removed and\nthen apply a matching algorithm:\n\n"
      ]
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "execution_count": null,
      "cell_type": "code",
      "source": [
        "text = data.text()\n\nsrc = np.array([[0, 0], [0, 50], [300, 50], [300, 0]])\ndst = np.array([[155, 15], [65, 40], [260, 130], [360, 95]])\n\ntform3 = tf.ProjectiveTransform()\ntform3.estimate(src, dst)\nwarped = tf.warp(text, tform3, output_shape=(50, 300))\n\nfig, ax = plt.subplots(nrows=2, figsize=(8, 3))\n\nax[0].imshow(text, cmap=plt.cm.gray)\nax[0].plot(dst[:, 0], dst[:, 1], '.r')\nax[1].imshow(warped, cmap=plt.cm.gray)\n\nfor a in ax:\n    a.axis('off')\n\nplt.tight_layout()"
      ]
    }
  ],
  "nbformat": 4
}